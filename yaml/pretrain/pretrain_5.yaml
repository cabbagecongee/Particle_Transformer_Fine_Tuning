apiVersion: batch/v1
kind: Job
metadata:
  name: tn-job-pretrain-backbone-5
  namespace: cms-ml
spec:
  backoffLimit: 2
  template:
    spec:
      restartPolicy: Never
      # 1) Add tolerations for the taints you saw in `kubectl describe pod`
      tolerations:
        # tolerate *any* nautilus.io/issue taint
      - key: "nautilus.io/issue"
        operator: "Exists"
        effect: "NoSchedule"
        # tolerate any reservation taint
      - key: "nautilus.io/reservation"
        operator: "Exists"
        effect: "NoSchedule"
      containers:
      - name: tn-job-pretrain-backbone-5
        image: pytorch/pytorch:2.2.0-cuda12.1-cudnn8-runtime
        command:
        - sh
        - -c
        - |
          apt update && \
          apt install -y wget && \
          cd /mnt/repo/Particle_Transformer_Fine_Tunning && \
          echo "[INFO] Installing Python packages..." && \
          pip install --upgrade pip && \
          pip install accelerate \
                      numpy pandas matplotlib tqdm scikit-learn seaborn \
                      weaver-core jetnet tensorboard aiohttp requests pyarrow==14.0.1 && \
          echo "[INFO] Checking GPU availability..." && \
          nvidia-smi && \
          mkdir -p /mnt/data/output && \
          accelerate launch --num_processes 8 train5.py
        volumeMounts:
        - name: git-repo
          mountPath: /mnt/repo
        - name: tn-pvc-many-jetclass2
          mountPath: /mnt/data
        resources:
          limits:
            memory: "16Gi"
            cpu: "1"
            nvidia.com/gpu: "8"
          requests:
            memory: "16Gi"
            cpu: "1"
            nvidia.com/gpu: "8"

      initContainers:
      - name: init-clone-repo
        image: alpine/git
        args:
        - clone
        - --single-branch
        - https://github.com/cabbagecongee/Particle_Transformer_Fine_Tunning.git
        - /mnt/repo/Particle_Transformer_Fine_Tunning
        volumeMounts:
        - name: git-repo
          mountPath: /mnt/repo
        resources:
          limits:
            memory: "900Mi"
            cpu: "1"
          requests:
            memory: "900Mi"
            cpu: "1"

      volumes:
      - name: git-repo
        emptyDir: {}
      - name: tn-pvc-many-jetclass2
        persistentVolumeClaim:
          claimName: tn-pvc-many-jetclass2

      # affinity:
      #   nodeAffinity:
      #     preferredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #       - matchExpressions:
      #         - key: kubernetes.io/hostname
      #           operator: NotIn
      #           values:
      #             - gpn-fiona-mizzou-2.rnet.missouri.edu
      #             - rci-nrp-gpu-05.sdsu.edu
      #             - node-2-2.sdsc.optiputer.net
      #         - key: nvidia.com/gpu.product
      #           operator: In
      #           values:
      #             - Tesla-V100-SXM2-32GB	
      #             - NVIDIA-A40	
      #             - NVIDIA-L40
      #             - NVIDIA-RTX-A6000	
      #             - Quadro-RTX-8000	
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            # 1) preference on hostname exclusion
          - weight:  50
            preference:
              matchExpressions:
                - key: kubernetes.io/hostname
                  operator: NotIn
                  values:
                    - gpn-fiona-mizzou-2.rnet.missouri.edu
                    - rci-nrp-gpu-05.sdsu.edu
                    - node-2-2.sdsc.optiputer.net

            # 2) preference on GPU type
          - weight: 100
            preference:
              matchExpressions:
                - key: nvidia.com/gpu.product
                  operator: In
                  values:
                    - Tesla-V100-SXM2-32GB
                    - NVIDIA-A40
                    - NVIDIA-L40
                    - NVIDIA-RTX-A6000
                    - Quadro-RTX-8000
